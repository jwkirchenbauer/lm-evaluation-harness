{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the outputs of the lm eval harness\n",
    "\n",
    "Especially the MMLU because tasks are not averaged for us to achive whast shown on leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/lm-evaluation-harness/$OUTPUT_DIR\"\n",
    "# OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/output\"\n",
    "OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/output/zero_shot\"\n",
    "# OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/output/rand_smooth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_fn(s):\n",
    "    if \"vicuna\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 1\n",
    "        elif \"para\" in s:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    if \"falcon\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 4\n",
    "        elif \"para\" in s:\n",
    "            return 5\n",
    "        else:\n",
    "            return 3\n",
    "    if \"guanaco\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 7\n",
    "        elif \"para\" in s:\n",
    "            return 8\n",
    "        else:\n",
    "            return 6\n",
    "    if \"alpaca_7b_hf\" in s:\n",
    "        return 9\n",
    "    if \"alpaca_7b_w_smooth\" in s:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_arc_challenge_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_arc_challenge_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_arc_challenge_broken.json\n",
      "{'vicuna_arc_challenge': [0.4377133105802048], 'vicuna_arc_challenge_broken': [0.2781569965870307], 'falcon_arc_challenge': [0.4283276450511945], 'falcon_arc_challenge_broken': [0.2738907849829352], 'guanaco_arc_challenge': [0.46331058020477817], 'guanaco_arc_challenge_broken': [0.2935153583617747]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_arc_challenge': 0.4377133105802048,\n",
       " 'vicuna_arc_challenge_broken': 0.2781569965870307,\n",
       " 'falcon_arc_challenge': 0.4283276450511945,\n",
       " 'falcon_arc_challenge_broken': 0.2738907849829352,\n",
       " 'guanaco_arc_challenge': 0.46331058020477817,\n",
       " 'guanaco_arc_challenge_broken': 0.2935153583617747}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"arc\" and that are files ending in .json\n",
    "target_metric = \"acc_norm\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"arc\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_hellaswag_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_hellaswag_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_hellaswag_broken.json\n",
      "{'vicuna_hellaswag': [0.7467635929097789], 'vicuna_hellaswag_broken': [0.355008962358096], 'falcon_hellaswag': [0.6972714598685521], 'falcon_hellaswag_broken': [0.3503286197968532], 'guanaco_hellaswag': [0.7839075881298546], 'guanaco_hellaswag_broken': [0.3800039832702649]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_hellaswag': 0.7467635929097789,\n",
       " 'vicuna_hellaswag_broken': 0.355008962358096,\n",
       " 'falcon_hellaswag': 0.6972714598685521,\n",
       " 'falcon_hellaswag_broken': 0.3503286197968532,\n",
       " 'guanaco_hellaswag': 0.7839075881298546,\n",
       " 'guanaco_hellaswag_broken': 0.3800039832702649}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"truthfulqa\" and that are files ending in .json\n",
    "target_metric = \"acc_norm\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"hellaswag\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_mmlu_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_mmlu_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_mmlu_broken.json\n",
      "{'vicuna_mmlu': [0.26, 0.4740740740740741, 0.4605263157894737, 0.51, 0.4679245283018868, 0.4375, 0.38, 0.37, 0.33, 0.4277456647398844, 0.28431372549019607, 0.54, 0.4, 0.21052631578947367, 0.4068965517241379, 0.30687830687830686, 0.36507936507936506, 0.29, 0.4774193548387097, 0.31527093596059114, 0.35, 0.5878787878787879, 0.5353535353535354, 0.6373056994818653, 0.43846153846153846, 0.23333333333333334, 0.42436974789915966, 0.31788079470198677, 0.6422018348623854, 0.41203703703703703, 0.5980392156862745, 0.620253164556962, 0.5381165919282511, 0.5725190839694656, 0.5950413223140496, 0.5740740740740741, 0.5337423312883436, 0.25, 0.6116504854368932, 0.6965811965811965, 0.56, 0.665389527458493, 0.5028901734104047, 0.2435754189944134, 0.5522875816993464, 0.5530546623794212, 0.5030864197530864, 0.33687943262411346, 0.3617992177314211, 0.4522058823529412, 0.4624183006535948, 0.4818181818181818, 0.5142857142857142, 0.6766169154228856, 0.68, 0.41566265060240964, 0.6432748538011696], 'vicuna_mmlu_broken': [0.24, 0.2814814814814815, 0.28289473684210525, 0.37, 0.32075471698113206, 0.2638888888888889, 0.28, 0.31, 0.28, 0.2947976878612717, 0.2647058823529412, 0.3, 0.3148936170212766, 0.22807017543859648, 0.3586206896551724, 0.25132275132275134, 0.31746031746031744, 0.23, 0.3258064516129032, 0.28078817733990147, 0.23, 0.3090909090909091, 0.3333333333333333, 0.3626943005181347, 0.30256410256410254, 0.2222222222222222, 0.29831932773109243, 0.2781456953642384, 0.28440366972477066, 0.2916666666666667, 0.3627450980392157, 0.4177215189873418, 0.34977578475336324, 0.24427480916030533, 0.2892561983471074, 0.37037037037037035, 0.26993865030674846, 0.2767857142857143, 0.36893203883495146, 0.3717948717948718, 0.31, 0.3231162196679438, 0.3063583815028902, 0.24916201117318434, 0.3300653594771242, 0.3536977491961415, 0.30246913580246915, 0.31560283687943264, 0.2926988265971317, 0.3161764705882353, 0.2777777777777778, 0.32727272727272727, 0.32653061224489793, 0.38308457711442784, 0.26, 0.2891566265060241, 0.3508771929824561], 'falcon_mmlu': [0.27, 0.23703703703703705, 0.20394736842105263, 0.4, 0.23018867924528302, 0.2638888888888889, 0.19, 0.23, 0.2, 0.2543352601156069, 0.23529411764705882, 0.29, 0.28085106382978725, 0.2631578947368421, 0.22758620689655173, 0.21957671957671956, 0.2698412698412698, 0.19, 0.24193548387096775, 0.19704433497536947, 0.29, 0.24848484848484848, 0.23232323232323232, 0.18652849740932642, 0.23333333333333334, 0.24444444444444444, 0.226890756302521, 0.2185430463576159, 0.23669724770642203, 0.16666666666666666, 0.2647058823529412, 0.28270042194092826, 0.33183856502242154, 0.3053435114503817, 0.2892561983471074, 0.2777777777777778, 0.2147239263803681, 0.30357142857142855, 0.24271844660194175, 0.28205128205128205, 0.3, 0.28607918263090676, 0.2514450867052023, 0.23798882681564246, 0.23529411764705882, 0.19292604501607716, 0.24691358024691357, 0.24468085106382978, 0.2333767926988266, 0.19852941176470587, 0.2581699346405229, 0.32727272727272727, 0.19183673469387755, 0.23880597014925373, 0.3, 0.29518072289156627, 0.30409356725146197], 'falcon_mmlu_broken': [0.22, 0.25925925925925924, 0.19736842105263158, 0.22, 0.24150943396226415, 0.24305555555555555, 0.2, 0.25, 0.24, 0.24855491329479767, 0.3235294117647059, 0.32, 0.2723404255319149, 0.30701754385964913, 0.23448275862068965, 0.25132275132275134, 0.2222222222222222, 0.33, 0.25483870967741934, 0.22660098522167488, 0.27, 0.2, 0.2222222222222222, 0.21761658031088082, 0.258974358974359, 0.24444444444444444, 0.24369747899159663, 0.2251655629139073, 0.23119266055045873, 0.18055555555555555, 0.23039215686274508, 0.25316455696202533, 0.33183856502242154, 0.21374045801526717, 0.24793388429752067, 0.23148148148148148, 0.22085889570552147, 0.2857142857142857, 0.1650485436893204, 0.29914529914529914, 0.26, 0.2988505747126437, 0.2398843930635838, 0.2201117318435754, 0.24509803921568626, 0.28938906752411575, 0.26851851851851855, 0.24822695035460993, 0.25945241199478486, 0.20220588235294118, 0.24673202614379086, 0.3181818181818182, 0.20408163265306123, 0.24875621890547264, 0.28, 0.29518072289156627, 0.19883040935672514], 'guanaco_mmlu': [0.27, 0.4222222222222222, 0.3684210526315789, 0.35, 0.39622641509433965, 0.3055555555555556, 0.21, 0.18, 0.29, 0.27167630057803466, 0.2647058823529412, 0.33, 0.3276595744680851, 0.23684210526315788, 0.2689655172413793, 0.24074074074074073, 0.2619047619047619, 0.29, 0.34516129032258064, 0.2955665024630542, 0.33, 0.4, 0.3181818181818182, 0.32642487046632124, 0.3, 0.23703703703703705, 0.29831932773109243, 0.23841059602649006, 0.3357798165137615, 0.2222222222222222, 0.37745098039215685, 0.33755274261603374, 0.3901345291479821, 0.33587786259541985, 0.5702479338842975, 0.32407407407407407, 0.4049079754601227, 0.2857142857142857, 0.33980582524271846, 0.4700854700854701, 0.38, 0.44699872286079184, 0.38439306358381503, 0.24804469273743016, 0.37254901960784315, 0.39228295819935693, 0.41358024691358025, 0.25177304964539005, 0.2985658409387223, 0.23529411764705882, 0.36764705882352944, 0.37272727272727274, 0.27346938775510204, 0.47761194029850745, 0.38, 0.3132530120481928, 0.4152046783625731], 'guanaco_mmlu_broken': [0.2, 0.26666666666666666, 0.24342105263157895, 0.28, 0.3320754716981132, 0.22916666666666666, 0.25, 0.26, 0.36, 0.2947976878612717, 0.3333333333333333, 0.3, 0.2170212765957447, 0.21052631578947367, 0.27586206896551724, 0.2328042328042328, 0.31746031746031744, 0.26, 0.25161290322580643, 0.24630541871921183, 0.33, 0.2727272727272727, 0.26262626262626265, 0.25906735751295334, 0.3076923076923077, 0.3111111111111111, 0.24789915966386555, 0.2052980132450331, 0.26972477064220185, 0.25462962962962965, 0.2647058823529412, 0.20675105485232068, 0.31390134529147984, 0.1984732824427481, 0.34710743801652894, 0.17592592592592593, 0.27607361963190186, 0.24107142857142858, 0.34951456310679613, 0.2564102564102564, 0.32, 0.2413793103448276, 0.23121387283236994, 0.264804469273743, 0.23202614379084968, 0.2572347266881029, 0.30246913580246915, 0.25886524822695034, 0.25684485006518903, 0.25735294117647056, 0.26633986928104575, 0.32727272727272727, 0.3020408163265306, 0.29850746268656714, 0.16, 0.23493975903614459, 0.2631578947368421]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_mmlu': 0.4647059622192778,\n",
       " 'vicuna_mmlu_broken': 0.3042731115988958,\n",
       " 'falcon_mmlu': 0.25115574368589466,\n",
       " 'falcon_mmlu_broken': 0.24839982070031125,\n",
       " 'guanaco_mmlu': 0.32967140965577024,\n",
       " 'guanaco_mmlu_broken': 0.2664247951124865}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level thpugh)\n",
    "# and filter for rows that contain \"mmlu\" and that are files ending in .json\n",
    "target_metric = \"acc\"\n",
    "\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"mmlu\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "average_accuracies = {name:np.mean(accs) for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/vicuna_truthfulqa_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/falcon_truthfulqa_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/zero_shot/guanaco_truthfulqa_broken.json\n",
      "{'vicuna_truthfulqa': [0.4900800354558949], 'vicuna_truthfulqa_broken': [0.45652632146852323], 'falcon_truthfulqa': [0.44068381814512897], 'falcon_truthfulqa_broken': [0.4643838721599166], 'guanaco_truthfulqa': [0.38926221444467723], 'guanaco_truthfulqa_broken': [0.4265864560184022]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_truthfulqa': 0.4900800354558949,\n",
       " 'vicuna_truthfulqa_broken': 0.45652632146852323,\n",
       " 'falcon_truthfulqa': 0.44068381814512897,\n",
       " 'falcon_truthfulqa_broken': 0.4643838721599166,\n",
       " 'guanaco_truthfulqa': 0.38926221444467723,\n",
       " 'guanaco_truthfulqa_broken': 0.4265864560184022}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"truthfulqa\" and that are files ending in .json\n",
    "target_metric = \"mc2\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"truthfulqa\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
