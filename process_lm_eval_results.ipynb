{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the outputs of the lm eval harness\n",
    "\n",
    "Especially the MMLU because tasks are not averaged for us to achive whast shown on leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/lm-evaluation-harness/$OUTPUT_DIR\"\n",
    "OUTPUT_DIR = \"/cmlscratch/jkirchen/adv-llm-root/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_fn(s):\n",
    "    if \"vicuna\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 1\n",
    "        elif \"para\" in s:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    if \"falcon\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 4\n",
    "        elif \"para\" in s:\n",
    "            return 5\n",
    "        else:\n",
    "            return 3\n",
    "    if \"guanaco\" in s:\n",
    "        if \"broken\" in s:\n",
    "            return 7\n",
    "        elif \"para\" in s:\n",
    "            return 8\n",
    "        else:\n",
    "            return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_arc_challenge_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_arc_challenge_para.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_arc_challenge_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_arc_challenge_para.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_arc_challenge.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_arc_challenge_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_arc_challenge_para.json\n",
      "{'vicuna_arc_challenge': [0.5349829351535836], 'vicuna_arc_challenge_broken': [0.2883959044368601], 'vicuna_arc_challenge_para': [0.39505119453924914], 'falcon_arc_challenge': [0.45819112627986347], 'falcon_arc_challenge_broken': [0.2773037542662116], 'falcon_arc_challenge_para': [0.4044368600682594], 'guanaco_arc_challenge': [0.5221843003412969], 'guanaco_arc_challenge_broken': [0.2713310580204778], 'guanaco_arc_challenge_para': [0.3916382252559727]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_arc_challenge': 0.5349829351535836,\n",
       " 'vicuna_arc_challenge_broken': 0.2883959044368601,\n",
       " 'vicuna_arc_challenge_para': 0.39505119453924914,\n",
       " 'falcon_arc_challenge': 0.45819112627986347,\n",
       " 'falcon_arc_challenge_broken': 0.2773037542662116,\n",
       " 'falcon_arc_challenge_para': 0.4044368600682594,\n",
       " 'guanaco_arc_challenge': 0.5221843003412969,\n",
       " 'guanaco_arc_challenge_broken': 0.2713310580204778,\n",
       " 'guanaco_arc_challenge_para': 0.3916382252559727}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"arc\" and that are files ending in .json\n",
    "target_metric = \"acc_norm\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"arc\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_hellaswag_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_hellaswag_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_hellaswag.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_hellaswag_broken.json\n",
      "{'vicuna_hellaswag': [0.7751443935471022], 'vicuna_hellaswag_broken': [0.359788886675961], 'falcon_hellaswag': [0.7085241983668592], 'falcon_hellaswag_broken': [0.3397729535949014], 'guanaco_hellaswag': [0.8019318860784704], 'guanaco_hellaswag_broken': [0.3826926906990639]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_hellaswag': 0.7751443935471022,\n",
       " 'vicuna_hellaswag_broken': 0.359788886675961,\n",
       " 'falcon_hellaswag': 0.7085241983668592,\n",
       " 'falcon_hellaswag_broken': 0.3397729535949014,\n",
       " 'guanaco_hellaswag': 0.8019318860784704,\n",
       " 'guanaco_hellaswag_broken': 0.3826926906990639}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"truthfulqa\" and that are files ending in .json\n",
    "target_metric = \"acc_norm\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"hellaswag\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_mmlu_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_mmlu_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_mmlu.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_mmlu_broken.json\n",
      "{'vicuna_mmlu': [0.26, 0.4222222222222222, 0.48026315789473684, 0.47, 0.5018867924528302, 0.4513888888888889, 0.4, 0.41, 0.33, 0.36416184971098264, 0.2549019607843137, 0.57, 0.37872340425531914, 0.23684210526315788, 0.4413793103448276, 0.2962962962962963, 0.3412698412698413, 0.23, 0.46774193548387094, 0.33497536945812806, 0.39, 0.5757575757575758, 0.5858585858585859, 0.6528497409326425, 0.4282051282051282, 0.2074074074074074, 0.41596638655462187, 0.2847682119205298, 0.5981651376146789, 0.4027777777777778, 0.6078431372549019, 0.5949367088607594, 0.5381165919282511, 0.549618320610687, 0.5619834710743802, 0.5833333333333334, 0.5276073619631901, 0.25892857142857145, 0.6019417475728155, 0.6923076923076923, 0.49, 0.6334610472541508, 0.523121387283237, 0.2446927374301676, 0.49019607843137253, 0.49517684887459806, 0.5154320987654321, 0.32978723404255317, 0.35267275097783574, 0.5, 0.434640522875817, 0.509090909090909, 0.5387755102040817, 0.6318407960199005, 0.63, 0.4036144578313253, 0.6783625730994152], 'vicuna_mmlu_broken': [0.29, 0.32592592592592595, 0.34868421052631576, 0.31, 0.33962264150943394, 0.20833333333333334, 0.17, 0.25, 0.27, 0.3352601156069364, 0.24509803921568626, 0.26, 0.31063829787234043, 0.22807017543859648, 0.2827586206896552, 0.23809523809523808, 0.23015873015873015, 0.27, 0.3, 0.2561576354679803, 0.3, 0.28484848484848485, 0.2828282828282828, 0.32642487046632124, 0.258974358974359, 0.2037037037037037, 0.3277310924369748, 0.2980132450331126, 0.3376146788990826, 0.2962962962962963, 0.3333333333333333, 0.29957805907172996, 0.2600896860986547, 0.3435114503816794, 0.35537190082644626, 0.3148148148148148, 0.27607361963190186, 0.22321428571428573, 0.2815533980582524, 0.41452991452991456, 0.29, 0.3243933588761175, 0.3063583815028902, 0.24581005586592178, 0.3104575163398693, 0.3054662379421222, 0.2808641975308642, 0.25886524822695034, 0.26988265971316816, 0.3161764705882353, 0.2875816993464052, 0.38181818181818183, 0.2897959183673469, 0.34328358208955223, 0.33, 0.26506024096385544, 0.28654970760233917], 'falcon_mmlu': [0.29, 0.21481481481481482, 0.23684210526315788, 0.34, 0.2490566037735849, 0.24305555555555555, 0.19, 0.3, 0.25, 0.2774566473988439, 0.18627450980392157, 0.3, 0.2851063829787234, 0.2543859649122807, 0.2689655172413793, 0.22486772486772486, 0.2777777777777778, 0.27, 0.2032258064516129, 0.2019704433497537, 0.26, 0.2545454545454545, 0.24242424242424243, 0.23834196891191708, 0.24102564102564103, 0.18518518518518517, 0.23949579831932774, 0.2119205298013245, 0.25321100917431194, 0.16203703703703703, 0.23039215686274508, 0.27848101265822783, 0.3542600896860987, 0.2748091603053435, 0.2396694214876033, 0.24074074074074073, 0.24539877300613497, 0.32142857142857145, 0.27184466019417475, 0.2863247863247863, 0.34, 0.2771392081736909, 0.25722543352601157, 0.25027932960893856, 0.23529411764705882, 0.2379421221864952, 0.2962962962962963, 0.2375886524822695, 0.23598435462842243, 0.35661764705882354, 0.23039215686274508, 0.3181818181818182, 0.18775510204081633, 0.22885572139303484, 0.34, 0.30120481927710846, 0.3216374269005848], 'falcon_mmlu_broken': [0.27, 0.24444444444444444, 0.21052631578947367, 0.2, 0.24528301886792453, 0.2152777777777778, 0.31, 0.26, 0.23, 0.23699421965317918, 0.14705882352941177, 0.3, 0.2765957446808511, 0.2719298245614035, 0.20689655172413793, 0.23809523809523808, 0.2698412698412698, 0.27, 0.19032258064516128, 0.22660098522167488, 0.24, 0.2545454545454545, 0.2878787878787879, 0.24870466321243523, 0.2512820512820513, 0.25555555555555554, 0.25630252100840334, 0.23178807947019867, 0.23302752293577983, 0.18981481481481483, 0.22058823529411764, 0.3080168776371308, 0.2825112107623318, 0.22137404580152673, 0.3140495867768595, 0.24074074074074073, 0.25766871165644173, 0.2767857142857143, 0.24271844660194175, 0.2948717948717949, 0.25, 0.26309067688378035, 0.23699421965317918, 0.25139664804469275, 0.25163398692810457, 0.2572347266881029, 0.30246913580246915, 0.2198581560283688, 0.24185136897001303, 0.31985294117647056, 0.2565359477124183, 0.22727272727272727, 0.24081632653061225, 0.23880597014925373, 0.26, 0.2891566265060241, 0.30409356725146197], 'guanaco_mmlu': [0.27, 0.3925925925925926, 0.32894736842105265, 0.32, 0.43018867924528303, 0.375, 0.29, 0.28, 0.27, 0.2832369942196532, 0.21568627450980393, 0.41, 0.3659574468085106, 0.22807017543859648, 0.31724137931034485, 0.2671957671957672, 0.20634920634920634, 0.34, 0.3387096774193548, 0.33497536945812806, 0.34, 0.43636363636363634, 0.37373737373737376, 0.41450777202072536, 0.35128205128205126, 0.22962962962962963, 0.31932773109243695, 0.2582781456953642, 0.46238532110091746, 0.24074074074074073, 0.36764705882352944, 0.3924050632911392, 0.4484304932735426, 0.3435114503816794, 0.5950413223140496, 0.39814814814814814, 0.3619631901840491, 0.26785714285714285, 0.32038834951456313, 0.49572649572649574, 0.42, 0.44316730523627074, 0.37572254335260113, 0.2424581005586592, 0.39215686274509803, 0.37942122186495175, 0.37962962962962965, 0.2907801418439716, 0.29726205997392435, 0.4338235294117647, 0.34967320261437906, 0.43636363636363634, 0.32653061224489793, 0.43283582089552236, 0.48, 0.3674698795180723, 0.4853801169590643], 'guanaco_mmlu_broken': [0.19, 0.2740740740740741, 0.2565789473684211, 0.27, 0.2679245283018868, 0.2916666666666667, 0.26, 0.22, 0.25, 0.28901734104046245, 0.17647058823529413, 0.24, 0.2765957446808511, 0.2543859649122807, 0.22758620689655173, 0.26455026455026454, 0.2777777777777778, 0.23, 0.23225806451612904, 0.270935960591133, 0.3, 0.2727272727272727, 0.22727272727272727, 0.27461139896373055, 0.258974358974359, 0.2777777777777778, 0.25210084033613445, 0.271523178807947, 0.25137614678899084, 0.2824074074074074, 0.27450980392156865, 0.21940928270042195, 0.2825112107623318, 0.3053435114503817, 0.2809917355371901, 0.24074074074074073, 0.22699386503067484, 0.22321428571428573, 0.23300970873786409, 0.23076923076923078, 0.25, 0.26436781609195403, 0.2514450867052023, 0.2122905027932961, 0.2581699346405229, 0.3054662379421222, 0.26851851851851855, 0.23404255319148937, 0.26988265971316816, 0.31985294117647056, 0.24836601307189543, 0.33636363636363636, 0.2693877551020408, 0.2885572139303483, 0.34, 0.26506024096385544, 0.26900584795321636]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_mmlu': 0.4579173855240306,\n",
       " 'vicuna_mmlu_broken': 0.29087143678178295,\n",
       " 'falcon_mmlu': 0.258732110518809,\n",
       " 'falcon_mmlu_broken': 0.2515641164133633,\n",
       " 'guanaco_mmlu': 0.3546350300062799,\n",
       " 'guanaco_mmlu_broken': 0.2606467293366766}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level thpugh)\n",
    "# and filter for rows that contain \"mmlu\" and that are files ending in .json\n",
    "target_metric = \"acc\"\n",
    "\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"mmlu\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "average_accuracies = {name:np.mean(accs) for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_truthfulqa_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/vicuna_truthfulqa_para.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_truthfulqa_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/falcon_truthfulqa_para.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_truthfulqa.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_truthfulqa_broken.json\n",
      "/cmlscratch/jkirchen/adv-llm-root/output/guanaco_truthfulqa_para.json\n",
      "{'vicuna_truthfulqa': [0.4900800354558949], 'vicuna_truthfulqa_broken': [0.4508368412481562], 'vicuna_truthfulqa_para': [0.45707453036411666], 'falcon_truthfulqa': [0.44068381814512897], 'falcon_truthfulqa_broken': [0.46178305139123815], 'falcon_truthfulqa_para': [0.48122278202967333], 'guanaco_truthfulqa': [0.38926221444467723], 'guanaco_truthfulqa_broken': [0.4317771362213596], 'guanaco_truthfulqa_para': [0.44485951597566464]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vicuna_truthfulqa': 0.4900800354558949,\n",
       " 'vicuna_truthfulqa_broken': 0.4508368412481562,\n",
       " 'vicuna_truthfulqa_para': 0.45707453036411666,\n",
       " 'falcon_truthfulqa': 0.44068381814512897,\n",
       " 'falcon_truthfulqa_broken': 0.46178305139123815,\n",
       " 'falcon_truthfulqa_para': 0.48122278202967333,\n",
       " 'guanaco_truthfulqa': 0.38926221444467723,\n",
       " 'guanaco_truthfulqa_broken': 0.4317771362213596,\n",
       " 'guanaco_truthfulqa_para': 0.44485951597566464}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all files in OUTPUT_DIR (only top level)\n",
    "# same except this time and filter for rows that contain \"truthfulqa\" and that are files ending in .json\n",
    "target_metric = \"mc2\"\n",
    "top_level_files = [f for f in os.listdir(OUTPUT_DIR) if not os.path.isdir(f)]\n",
    "fn = lambda f: (\"truthfulqa\" in f and f.endswith(\".json\"))\n",
    "all_files = [f\"{OUTPUT_DIR}/{f}\" for f in top_level_files if fn(f)]\n",
    "\n",
    "all_files = sorted(all_files, key=order_fn)\n",
    "\n",
    "for f in all_files:\n",
    "    print(f)\n",
    "\n",
    "all_data = []\n",
    "for f in all_files:\n",
    "    with open(f, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_data.append(data)\n",
    "\n",
    "# print(json.dumps(all_data[0], indent=4))\n",
    "\n",
    "all_accuracies = {}\n",
    "\n",
    "for f,data in zip(all_files, all_data):\n",
    "    run_name = (f.split(\"/\")[-1]).split(\".\")[0]\n",
    "    per_task_metrics = data[\"results\"]\n",
    "\n",
    "    all_accs = [metrics[target_metric] for task,metrics in per_task_metrics.items()]\n",
    "    all_accuracies[run_name] = all_accs\n",
    "\n",
    "print(all_accuracies)\n",
    "\n",
    "# we don't need to \"average\" now just take first\n",
    "average_accuracies = {name:accs[0] for name,accs in all_accuracies.items()}\n",
    "\n",
    "average_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-llm-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
